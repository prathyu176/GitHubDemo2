{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_dataset (svm,knn,LR)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathyu176/GitHubDemo2/blob/master/iris_dataset_(svm%2Cknn%2CLR).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb33lxztAaGL",
        "colab_type": "text"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlIaW50Upwwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "iris = datasets.load_iris()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjIXW9L8qGnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris.data #prints all the data from the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGRx8Ed6qT1g",
        "colab_type": "code",
        "outputId": "60587251-bb15-4968-b270-746f42d5a603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "iris['feature_names']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oin9Rh4erFcv",
        "colab_type": "code",
        "outputId": "6b56ad97-8907-4960-acb7-4ed3d83797c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "iris.target #we will be predicting"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltfBHEPBqkY4",
        "colab_type": "code",
        "outputId": "d463caaa-7c7d-49fc-ff9c-6cc9aa782856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNnJ3nEDrV1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = iris.data  #independent variable, it contains features from the iris dataset                   #here we are only considering first two features \n",
        "y= iris.target #dependent variable, it is the attribute of the dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKmc4lEAtdYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AvH77dDvEFh",
        "colab_type": "code",
        "outputId": "22ff6b1e-943f-4634-9678-0359a8414e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import sklearn.svm\n",
        "\n",
        "model = svm.SVC(kernel='linear') #convert non seperable problem to seperable\n",
        "\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ra0MtATwjLu",
        "colab_type": "code",
        "outputId": "01679a0d-b043-4b03-fe91-ec4821e97985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_predict = model.predict(x_test)\n",
        "y_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 2, 1, 0, 0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX9G4CFFw0bu",
        "colab_type": "code",
        "outputId": "eb98acce-f2d9-429b-9cae-be063884d1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print (accuracy_score(y_test,y_predict))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk8qDdzjAcUq",
        "colab_type": "text"
      },
      "source": [
        "**K Nearest Neighbor (KNN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Jm1VSABZaN",
        "colab_type": "code",
        "outputId": "25acd5ec-5d31-44f9-9ab1-c8d2f8424a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model= KNeighborsClassifier()\n",
        "model.fit(x_train,y_train)\n",
        "prediction=model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print (accuracy_score(y_test,prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48vfuyHuDPcZ",
        "colab_type": "text"
      },
      "source": [
        "**Logistical Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbaqDMKDRs5",
        "colab_type": "code",
        "outputId": "3c0a6094-965f-4020-86c9-2d620384f26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "x= iris.data\n",
        "y= iris.target\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log =LogisticRegression()\n",
        "log.fit(x,y)\n",
        "a=np.array([5.7,2.8,4.1,1.3])\n",
        "log.predict([a])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ojnJfd7QxMt",
        "colab_type": "text"
      },
      "source": [
        "#Execute a Decision Tree with IRIS Data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yzmIr9pQ-Qv",
        "colab_type": "code",
        "outputId": "7c916fe0-126b-4104-b586-62e5b05cbbc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import Libraries \n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#Import data\n",
        "iris=datasets.load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "#Split data\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2)\n",
        "#define model\n",
        "model=DecisionTreeClassifier()\n",
        "#fit model\n",
        "model.fit(x_train,y_train)\n",
        "#predict model\n",
        "prediction=model.predict(x_test)\n",
        "#find accuracy\n",
        "acc=accuracy_score(y_test,prediction)\n",
        "acc\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndt_mrOa_7Q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as seabornInstance \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ4n9xLeEYqj",
        "colab_type": "code",
        "outputId": "c382bbc0-a850-4e3f-9dc5-614521717d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVoMKKdXgH5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('https://drive.google.com/open?id=1fiHg5DyvQeRC4SyhsVnje5dhJNyVWpO1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbxqWpC3FfeQ",
        "colab_type": "code",
        "outputId": "1fd92c59-f26a-41c2-e5f9-51fc6533ef7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "dataset.describe()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docs-eaclivu:false</th>\n",
              "      <th>docs-ndt:\"Untitled Texmex\"</th>\n",
              "      <th>docs-sfcnidtwi:false</th>\n",
              "      <th>docs-as:\"\"</th>\n",
              "      <th>docs-mriim:1800000</th>\n",
              "      <th>docs-eccbs:false</th>\n",
              "      <th>docs-mmpt:15000</th>\n",
              "      <th>docs-erd:false</th>\n",
              "      <th>docs-uootuns:false</th>\n",
              "      <th>docs-amawso:false</th>\n",
              "      <th>docs-pid:\"\"</th>\n",
              "      <th>docs-ebbouf:false</th>\n",
              "      <th>docs-eali:false</th>\n",
              "      <th>docs-elcn:false</th>\n",
              "      <th>docs-egs:false</th>\n",
              "      <th>docs-eeott:false</th>\n",
              "      <th>docs-eemv:false</th>\n",
              "      <th>docs-ececs:false</th>\n",
              "      <th>docs-edlo:false</th>\n",
              "      <th>docs-ecas:false</th>\n",
              "      <th>docs-ecenpik:false</th>\n",
              "      <th>docs-esdr:true</th>\n",
              "      <th>docs-elri:false</th>\n",
              "      <th>ecid:true</th>\n",
              "      <th>docs-enct:false</th>\n",
              "      <th>docs-emtrlrc:false</th>\n",
              "      <th>docs-mtrb3c:\"\"</th>\n",
              "      <th>docs-agdc:false</th>\n",
              "      <th>docs-ecqlr:false</th>\n",
              "      <th>docs-elsr:false</th>\n",
              "      <th>docs-emtrb3r:false</th>\n",
              "      <th>docs-eonm:false</th>\n",
              "      <th>docs-rldce:false</th>\n",
              "      <th>docs-sasic:false</th>\n",
              "      <th>docs-edamc:false</th>\n",
              "      <th>docs-edomic:false</th>\n",
              "      <th>docs-eesi:false</th>\n",
              "      <th>docs-efoecc:false</th>\n",
              "      <th>docs-elds:false</th>\n",
              "      <th>docs-mcssa:false</th>\n",
              "      <th>...</th>\n",
              "      <th>0.30</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.33</th>\n",
              "      <th>null.24</th>\n",
              "      <th>[[\"\"</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.36</th>\n",
              "      <th>null.27</th>\n",
              "      <th>[\"5061451\"</th>\n",
              "      <th>google\\\\.(com|ru|ca|by|kz|com\\\\.mx|com\\\\.tr)$</th>\n",
              "      <th>1]]</th>\n",
              "      <th>[1.2</th>\n",
              "      <th>1.7</th>\n",
              "      <th>0.38</th>\n",
              "      <th>27043</th>\n",
              "      <th>25.4</th>\n",
              "      <th>USA.1</th>\n",
              "      <th>en.2</th>\n",
              "      <th>265367620.0</th>\n",
              "      <th>8</th>\n",
              "      <th>0.009999999776482582</th>\n",
              "      <th>0.39</th>\n",
              "      <th>0.40</th>\n",
              "      <th>null.28</th>\n",
              "      <th>null.29</th>\n",
              "      <th>0.41</th>\n",
              "      <th>0.42</th>\n",
              "      <th>Unnamed: 407</th>\n",
              "      <th>null.30</th>\n",
              "      <th>null.31</th>\n",
              "      <th>1.8</th>\n",
              "      <th>njZoXeXuAcXtzgLwz4mgCw]</th>\n",
              "      <th>[[null</th>\n",
              "      <th>null.32</th>\n",
              "      <th>null.33</th>\n",
              "      <th>https://www.gstatic.com/og/_/js/k=og.qtm.en_US.Fz5SGVpR4OA.O/rt=j/m=q_d,qmutsd/exm=qaaw,qabr,qadd,qaid,qebr,qein,qhaw,qhbr,qhch,qhga,qhid,qhin,qhpr/d=1/ed=1/rs=AA2YrTtM2vqYMsoMRYyLXnVEdoWARzvsPQ]]</th>\n",
              "      <th>null.34</th>\n",
              "      <th>null.35</th>\n",
              "      <th>[\"\"]]]</th>\n",
              "      <th>};this.gbar_=this.gbar_||{};(function(_){var window=this;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       docs-eaclivu:false  ...  };this.gbar_=this.gbar_||{};(function(_){var window=this;\n",
              "count                 1.0  ...                                                0.0        \n",
              "mean                 64.0  ...                                                NaN        \n",
              "std                   NaN  ...                                                NaN        \n",
              "min                  64.0  ...                                                NaN        \n",
              "25%                  64.0  ...                                                NaN        \n",
              "50%                  64.0  ...                                                NaN        \n",
              "75%                  64.0  ...                                                NaN        \n",
              "max                  64.0  ...                                                NaN        \n",
              "\n",
              "[8 rows x 156 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21KxWmWGAPwY",
        "colab_type": "code",
        "outputId": "b68de34d-3f7b-40f8-9437-39e2f49322b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.scatter(x,y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzaDrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycWR8lW6AR7j",
        "colab_type": "code",
        "outputId": "f4b001da-532b-4eb4-93e6-cdd4391b07ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = np.array([[1,2],\n",
        "             [5,8],\n",
        "             [1.5,1.8],\n",
        "             [8,8],\n",
        "             [1,0.6],\n",
        "             [9,11]])\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NggBYxhqAWUB",
        "colab_type": "code",
        "outputId": "7756d5e5-1948-4a16-ad99-37f260995952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = np.array([0,1,0,1,0,1])\n",
        "\n",
        "y=y.reshape(-2,1)\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CLcVA9WAaRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = svm.SVC(kernel='linear', C = 1.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndrigeqyAb-O",
        "colab_type": "code",
        "outputId": "7b1f8f9b-087d-4ed3-ec16-df3de26b15ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "clf.fit(X,y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOWbsVTHAkf3",
        "colab_type": "code",
        "outputId": "f031d25a-7798-4c38-f531-1f5f8e7901cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "print(clf.predict([0.58,0.76]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-af3ccff20f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.58\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.76\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 454\u001b[0;31m                         accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.58 0.76].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wERzIvxcAqGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}